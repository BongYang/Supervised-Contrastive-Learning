{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from model import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root='./data/', transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)\n",
    "    \n",
    "# initialize the model\n",
    "model = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most likely prediction of the model\n",
    "pred = model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 386].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = model.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = model.get_activations(img).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7face9cfb190>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('data/o/1.png')\n",
    "heatmap = np.array(heatmap)\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./map.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 14])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmap.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08477114, 0.08477114, 0.08477114, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08477114, 0.08477114, 0.08477114, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08477114, 0.08477114, 0.08477114, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.0407134 , 0.0407134 , 0.0407134 , ..., 0.10287732, 0.10287732,\n",
       "        0.10287732],\n",
       "       [0.0407134 , 0.0407134 , 0.0407134 , ..., 0.10287732, 0.10287732,\n",
       "        0.10287732],\n",
       "       [0.0407134 , 0.0407134 , 0.0407134 , ..., 0.10287732, 0.10287732,\n",
       "        0.10287732]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.resize(np.array(heatmap), (1920, 1440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('data/o/1.png')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ba8904a7508c20a32dc19c1f8fa3d55239839a35e1a944d3f3baf89b2936aac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
